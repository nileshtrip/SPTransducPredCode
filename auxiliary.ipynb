{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'nileshtrip'\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import transpose as trans\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import pickle\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_pos_def(A):\n",
    "    \n",
    "    \"\"\"Checks if matrix is positive-definite\"\"\"\n",
    "    \n",
    "    if np.array_equal(A, A.T):\n",
    "        try:\n",
    "            np.linalg.cholesky(A)\n",
    "            return True\n",
    "        except np.linalg.LinAlgError:\n",
    "            raise Exception(\"Design Matrix not PSD\")\n",
    "    else:\n",
    "        raise Exception(\"Design Matrix Not Symmetric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cond(X):\n",
    "    \n",
    "    \"\"\"Computes condition number of the sample covariance of X\"\"\"\n",
    "\n",
    "    n,p = X.shape\n",
    "    Sig = X.T@X/float(n)\n",
    "    w, v = np.linalg.eigh(Sig) \n",
    "    \n",
    "    return max(w)/min(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construct a rotation matrix with first row equal to the renormalized x_test vector. The remaining orthonormal rows span the\n",
    "#orthogonal complement of x_test\n",
    "def rotate_matrix(x_test):\n",
    "    \n",
    "    \"\"\"Construct a rotation matrix with first row equal to the renormalized x_test vector. The remaining orthonormal rows span the\n",
    "    orthogonal complement (o.c.) of x_test\"\"\"\n",
    "    \n",
    "    p = x_test.shape[0]\n",
    "    \n",
    "    u = np.divide(x_test, np.linalg.norm(x_test))\n",
    "    m = np.eye(p)-np.outer(u,u)\n",
    "    \n",
    "    #Diagonalize projection matrix onto o.c.\n",
    "    eig_vals, eig_vectors = np.linalg.eigh(m)\n",
    "    U = eig_vectors[:, 1:]\n",
    "    D = np.diag(eig_vals[1:])\n",
    "    R = np.sqrt(D) @ np.transpose(U) #rows of R span o.c. of x_test\n",
    "    \n",
    "    #Stack u and R to form entire rotation matrix\n",
    "    B = np.vstack((u, R))\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_train_data(n, p, s, train_dist, x_scale, beta_scale, sigma):\n",
    "\n",
    "    \"\"\"Generates training data X_train, y_train and true coefficients and feature centering and scaling matrix\"\"\"\n",
    "    \n",
    "    # n number of datapoints\n",
    "    # p dimension\n",
    "    # s sparsity of \\beta_0 vector\n",
    "    # x_scale scales the design X \n",
    "    # beta_scales scales the coef vector\n",
    "    # sigma scales the additive noise \\epsilon\n",
    "    \n",
    "    \n",
    "    train_dist, dist_params = train_dist[0], train_dist[1]\n",
    "    \n",
    "    if train_dist==\"normal\":\n",
    "        X_train = np.random.normal(size=(n, p))*x_scale\n",
    "        \n",
    "        coef = beta_scale * np.random.normal(size=p) # build coef vector\n",
    "        coef[s:] = 0  # sparsify coef \n",
    "        \n",
    "        y_train = X_train @ coef #construct y-values\n",
    "        y_train += sigma * np.random.normal(size=n) #add epsilon noies\n",
    "    else:\n",
    "        raise Exception(\"Training Data Not Generated Correctly\")\n",
    "    \n",
    "    X_scaler = StandardScaler()\n",
    "    X_train = X_scaler.fit_transform(X_train) #define feature centering and scaling matrix\n",
    "    \n",
    "    kappa = cond(X_train)\n",
    "\n",
    "    return X_train, y_train, coef, X_scaler, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_test_data(n, p, s, coef, X_scaler, test_dist, x_scale, sigma):\n",
    "    \n",
    "    \"\"\"Generates test data X_train, y_train and true coefficients\"\"\"\n",
    "\n",
    "    # n number of datapoints\n",
    "    # p dimension\n",
    "    # x_scale scales the design X \n",
    "    # sigma scales the additive noise \\epsilon\n",
    "    \n",
    "    test_dist, dist_params = test_dist[0], test_dist[1]\n",
    "    \n",
    "    # Generate Test Data\n",
    "    if test_dist==\"normal\":\n",
    "        X_test = np.random.normal(size=(n, p))*x_scale\n",
    "    elif test_dist==\"normal+support_var\":\n",
    "        support_scale = dist_params[\"support_scale\"]\n",
    "        X = np.random.normal(size=(n, s))*x_scale*support_scale\n",
    "        X_test = np.hstack((X, np.zeros(shape=(n, p-s))))\n",
    "    elif test_dist==\"normal+support_rank_one\":\n",
    "        support_scale = dist_params[\"support_scale\"]\n",
    "        X = np.zeros(shape=(n, p))\n",
    "        for i in range(n):\n",
    "            eps = np.random.normal(size=1)[0]*x_scale*support_scale\n",
    "            for j in range(p):\n",
    "                X[i, j] = eps\n",
    "                \n",
    "        X_test = np.multiply(X, coef)\n",
    "    elif test_dist==\"normal+support_shift\":\n",
    "        X_test = np.random.normal(size=(n, p))*x_scale\n",
    "        mean_scale = dist_params[\"scale\"]\n",
    "        mean_shift=mean_scale*coef*x_scale\n",
    "        X_test+=mean_shift\n",
    "        \n",
    "    else:\n",
    "        raise Exception(\"Test Dist Set Incorrectly\")\n",
    "\n",
    "    # Construct y-values\n",
    "    y_test = X_test @ coef #construct y-values\n",
    "    y_test += sigma * np.random.normal(size=n) # Add noise if desired. Usually sigma=0 to compute RMRSE\n",
    "        \n",
    "    X_test = X_scaler.transform(X_test) # Scale/Transform Data using training data scaler.\n",
    "\n",
    "    return X_test, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
