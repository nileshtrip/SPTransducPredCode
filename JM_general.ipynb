{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import cvxpy as cvx\n",
    "import mosek\n",
    "import copy\n",
    "\n",
    "import mkl\n",
    "import pickle\n",
    "import os\n",
    "import ray\n",
    "import warnings\n",
    "import psutil\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from collections import OrderedDict\n",
    "from numpy import transpose as trans\n",
    "from collections import OrderedDict\n",
    "\n",
    "import subprocess\n",
    "subprocess.call(\"bash convert_files.sh\", shell=True)\n",
    "from auxiliary import is_pos_def, cond, rotate_matrix,  gen_train_data, gen_test_data\n",
    "from datasets import load_parkinson, load_triazines,  load_wine, load_fertility, load_forest_fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ray.init(object_store_memory=int(5e10), num_cpus=48,  redis_password=\"password54322423\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_linear(train_data, fit_intercept):\n",
    "    \n",
    "    \"\"\" LR fitter. fit_intercept determines whether or not to fit the y-intercept in the regression. This set to false by default. \"\"\"\n",
    "\n",
    "    X_train, y_train = train_data\n",
    "    n, p = X_train.shape\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "        \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    lr = LinearRegression(fit_intercept=fit_intercept)\n",
    "    lr.fit(X_train, y_train)\n",
    "        \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lasso(train_data, sigma, cv, fit_intercept, alpha_scaling, n_folds=5):\n",
    "    \n",
    "    \"\"\" Lasso fitter. If cv True uses CV to fit; if false will use alpha_scaling * \\sqrt{2 log p/n} as a regularizer\n",
    "    fit_intercept determines whether or not to fit the y-intercept in the regression. This set to false by default. \"\"\"\n",
    "\n",
    "    X_train, y_train = train_data\n",
    "    n, p = X_train.shape\n",
    "\n",
    "    from sklearn.linear_model import Lasso, LassoCV\n",
    "        \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Theoretically Optimal regularization and CV regularizers\n",
    "\n",
    "    if not cv:\n",
    "        alpha = alpha_scaling*sigma*math.sqrt(2* (math.log(p)/n))\n",
    "        lasso = Lasso(alpha=alpha, max_iter=5000, fit_intercept=fit_intercept)\n",
    "        lasso.fit(X_train, y_train)\n",
    "    else:\n",
    "        alphas = np.logspace(-6, 1, num=100)\n",
    "        lasso=LassoCV(max_iter=5000, cv=n_folds, alphas=alphas, fit_intercept=fit_intercept)\n",
    "        \n",
    "        # Run LassoCV with the metric for CV as MSE\n",
    "        lasso.fit(X_train, y_train)\n",
    "        \n",
    "    return lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_ridge(train_data, sigma, cv, fit_intercept, alpha_scaling=1.0):\n",
    "    \n",
    "    \"\"\" ridge regression fitter. If cv True uses CV to fit; if false will use alpha_scaling as a regularizer\n",
    "    fit_intercept determines whether or not to fit the y-intercept in the regression. This set to false by default. \"\"\"\n",
    "\n",
    "    X_train, y_train = train_data\n",
    "    n, p = X_train.shape\n",
    "\n",
    "    from sklearn.linear_model import Ridge, RidgeCV\n",
    "        \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Theoretically Optimal regularization and CV regularizers\n",
    "\n",
    "    if not cv:\n",
    "        alpha = alpha_scaling\n",
    "        ridge = Ridge(alpha=alpha, fit_intercept=fit_intercept)\n",
    "        ridge.fit(X_train, y_train)\n",
    "    else:\n",
    "        alphas = np.logspace(-6, 1, num=100)\n",
    "        ridge=RidgeCV(alphas=alphas, fit_intercept=fit_intercept)\n",
    "        \n",
    "        # Run LassoCV with the metric for CV as MSE\n",
    "        ridge.fit(X_train, y_train)\n",
    "\n",
    "    return ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_elastic(train_data, sigma, cv, fit_intercept, alpha_scaling=1.0, n_folds=5):\n",
    "    \n",
    "    \"\"\" elastic net fitter. If cv True uses CV to fit; if false will use alpha_scaling as a regularizer\n",
    "    fit_intercept determines whether or not to fit the y-intercept in the regression. This set to false by default. \"\"\"\n",
    "    \n",
    "    X_train, y_train = train_data\n",
    "    n, p = X_train.shape\n",
    "\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Theoretically Optimal regularization and CV regularizers\n",
    "    \n",
    "    if not cv:\n",
    "        alpha = alpha_scaling*sigma*math.sqrt(2*(math.log(p)/n))\n",
    "        elastic = ElasticNet(alpha=alpha, max_iter=5000, fit_intercept=fit_intercept)\n",
    "        elastic.fit(X_train, y_train)\n",
    "    else:\n",
    "        alphas = np.logspace(-6, 1, num=100)\n",
    "        ratio = [.1, .5, .7, .9, .95, .99, 1]\n",
    "        elastic=ElasticNetCV(max_iter=5000, cv=n_folds, l1_ratio = ratio, alphas=alphas, fit_intercept=fit_intercept)\n",
    "        \n",
    "        # Run LassoCV with the metric for CV as MSE\n",
    "        elastic.fit(X_train, y_train)\n",
    "\n",
    "    return elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def invert(X, x_star, lam, threads=1):\n",
    "\n",
    "    \"\"\"Parallel Function to solve JM program\"\"\"\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    mkl.set_num_threads(threads)\n",
    "    try:\n",
    "        n, p = X.shape\n",
    "        eps = 1e-12\n",
    "        Sigma_n = 1/float(n) * np.transpose(X) @ X  + eps*np.eye(p)\n",
    "        #adding epsilon to make matrix strictly p.s.d. or else cvxpy throws not DCP error (cannot recognize convexity of objective)\n",
    "\n",
    "        w = cvx.Variable(p)\n",
    "        obj = cvx.Minimize(cvx.quad_form(w, Sigma_n))\n",
    "        const = [cvx.norm(Sigma_n * w  - x_star, \"inf\") <= lam]\n",
    "\n",
    "        prob = cvx.Problem(obj, const)\n",
    "        sol = prob.solve(solver=cvx.MOSEK, mosek_params={mosek.iparam.num_threads: threads})\n",
    "        \n",
    "        return sol, w.value\n",
    "    except:\n",
    "        # If solver fails simply return None value for w\n",
    "        return math.inf, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_ws(X_train, X_test, lams, threads):\n",
    "    \n",
    "    \"\"\" Computes the entire set of w's needed for X_test using X_train \"\"\"\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    train_n, p = X_train.shape\n",
    "    test_n, p = X_test.shape\n",
    "\n",
    "    ids=[]\n",
    "    lam_deb, method = lams[0], lams[1]\n",
    "    for i in range(test_n):\n",
    "        x_star = X_test[i, :]\n",
    "        x_norm = np.linalg.norm(x_star, ord=2)\n",
    "        \n",
    "        # Computes Debiasing Correction using Theoretical Value of \\lambda_w\n",
    "        if method==\"theory\":\n",
    "            if (train_n >= 1.5*p):\n",
    "                lam_deb = .01*lam_deb\n",
    "                ids.append(invert.remote(X_train, x_star, lam=lam_deb*x_norm, threads=threads))\n",
    "            else:\n",
    "                ids.append(invert.remote(X_train, x_star, lam=lam_deb*x_norm, threads=threads))\n",
    "        # Computes Debiasing Correction for a fixed \\lambda_w\n",
    "        elif method==\"grid\":\n",
    "            ids.append(invert.remote(X_train, x_star, lam=lam_deb*x_norm, threads=threads))\n",
    "        else:\n",
    "            raise Exception(\"Aux Debiasing Set Incorrectly\")\n",
    "    vals = ray.get(ids) # Get values from Ray\n",
    "    ray.internal.free(ids) \n",
    "    \n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debias_base(train_data, base_model, X_test, ws):\n",
    "    \n",
    "    \"\"\"Computes JM Debiased Predictions with respect to the base model using base_model and learned ws\"\"\"\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    X_train, y_train = train_data\n",
    "    train_n, p = X_train.shape\n",
    "    test_n, p = X_test.shape\n",
    "    \n",
    "    beta = base_model.coef_\n",
    "    beta_int = base_model.intercept_\n",
    "\n",
    "    y_preds=np.zeros(test_n)\n",
    "    resid = np.transpose(X_train) @ (y_train-X_train @ beta-beta_int)\n",
    "    feasible=[]\n",
    "    for i in range(test_n):\n",
    "        x_star = X_test[i, :]\n",
    "        #Lasso Prediction\n",
    "        y_preds[i] = x_star.dot(beta) + beta_int\n",
    "        val, w = ws[i]\n",
    "        #debiasing correction\n",
    "        if val==math.inf:\n",
    "            feasible.append(False)\n",
    "        else:\n",
    "            y_preds[i] += 1/float(train_n) * np.ravel(w).dot(resid)\n",
    "            feasible.append(True)\n",
    "    \n",
    "    return y_preds, feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_JM_expt(data, main_reg, cv, fit_intercept, sigma, lams, threads):\n",
    "    # run an entire experiment for a given value of p, n, s. These will not use CV \n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data\n",
    "    \n",
    "    if main_reg==\"Lasso\":\n",
    "        f_main = fit_lasso((X_train, y_train), sigma=sigma, cv=cv, fit_intercept=fit_intercept, alpha_scaling=1.0, n_folds=5)\n",
    "    elif main_reg==\"Ridge\":\n",
    "        f_main = fit_ridge((X_train, y_train), sigma=sigma, cv=cv, fit_intercept=fit_intercept, alpha_scaling=1.0)\n",
    "    elif main_reg==\"Elastic\":\n",
    "        f_main = fit_elastic((X_train, y_train), sigma=sigma, cv=cv, fit_intercept=fit_intercept, alpha_scaling=1.0, n_folds=5)\n",
    "    else:\n",
    "        raise Exception(\"Main Reg Set Incorrectly\")    \n",
    "\n",
    "    f_main_preds = f_main.predict(X_test)\n",
    "    \n",
    "    lam_vals, method = lams[0], lams[1]\n",
    "    if method==\"theory\":\n",
    "        lam_deb = 1.5*math.sqrt(math.log(p)/train_n)\n",
    "        w = compute_ws(X_train, X_test, lams=(lam_deb, method), threads=threads)\n",
    "        deb_pred, feasible = debias_base((X_train, y_train), f_main, X_test, ws)\n",
    "        deb_preds = [deb_pred]\n",
    "        feasibles = [feasible]\n",
    "        ws = [w]\n",
    "    elif method==\"grid\":\n",
    "        deb_preds=[]\n",
    "        feasibles=[]\n",
    "        ws=[]\n",
    "        for lam_deb in lam_vals:\n",
    "            w = compute_ws(X_train, X_test, lams=(lam_deb, method), threads=threads)\n",
    "            deb_pred, feasible = debias_base((X_train, y_train), f_main, X_test, w)\n",
    "            deb_preds.append(deb_pred)\n",
    "            feasibles.append(feasible)\n",
    "            \n",
    "    kappa=cond(X_train)\n",
    "    \n",
    "    return deb_preds, f_main_preds, ws, y_test, kappa, feasibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_LinReg_expt(data, fit_intercept):\n",
    "    # run an entire experiment for a given value of p, n, s. These will not use CV \n",
    "    \n",
    "    X_train, y_train, X_test, y_test = data\n",
    "    f_main = fit_linear((X_train, y_train), fit_intercept=fit_intercept) \n",
    "    f_main_preds = f_main.predict(X_test)\n",
    "     \n",
    "    kappa=cond(X_train)\n",
    "    \n",
    "    return f_main_preds, y_test, kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_JM_expts(dataset, main_reg_param, cv, fit_intercept, sigma, lams, threads, parallel_params, folder_path):\n",
    "\n",
    "    # function to potentially parallelize experiments across various values of p, n, s and save data in pkl file\n",
    "    # Runs JM estimator on Real Data\n",
    "    save_data = OrderedDict()\n",
    "    \n",
    "    chunk_size, threads = parallel_params\n",
    "    main_reg = main_reg_param[\"method\"]\n",
    "    save_data[\"main_reg_params\"]=main_reg_param\n",
    "    save_data[\"dataset\"]=str(dataset)\n",
    "    save_data[\"main_reg\"]=\"CV\"+str(cv)\n",
    "    save_data[\"fit_intercept\"]=str(fit_intercept)\n",
    "    save_data[\"output\"] = \"deb_preds, main_preds, ws, y_test, kappa, feasibles, mu_y\"\n",
    "    save_data[\"sigma\"] = sigma\n",
    "    save_data[\"lam\"] = lams[0]\n",
    "    save_data[\"lam_method\"] = lams[1]\n",
    "\n",
    "    if dataset==\"Triazines\":\n",
    "        data=load_triazines(test_size=.20)\n",
    "    elif dataset==\"Wine\":\n",
    "        data=load_wine()\n",
    "    elif dataset==\"Parkinson\":\n",
    "        data=load_parkinson()\n",
    "    elif dataset==\"Fertility\":\n",
    "        data=load_fertility()\n",
    "    elif dataset==\"Fire\":\n",
    "        data=load_forest_fires()\n",
    "        \n",
    "    assert(fit_intercept==False, \"This should be set to false for all f regression. g_lasso has been manually set to include this\")\n",
    "    X_train, y_train, X_test, y_test = data\n",
    "    train_n, p = X_train.shape\n",
    "    test_n, _ = X_test.shape\n",
    "    #print(test_n)\n",
    "    mu_y = np.mean(y_train)\n",
    "    y_train = y_train - mu_y\n",
    "    \n",
    "    print(\"Starting\")\n",
    "\n",
    "    deb_preds=[]\n",
    "    lasso_preds=[]\n",
    "    y_tests=[] \n",
    "    kappas=[]\n",
    "    feasibles=[]\n",
    "\n",
    "    deb_pred, lasso_pred, w, y_test, kappa, feasible = run_JM_expt((X_train, y_train, X_test, y_test), main_reg=main_reg, cv=cv, fit_intercept=fit_intercept, sigma=sigma, lams=lams, threads=threads)\n",
    "    deb_preds.append([i+mu_y for i in deb_pred])\n",
    "    lasso_preds.append(lasso_pred+mu_y)\n",
    "    y_tests.append(y_test)\n",
    "    kappas.append(kappa)\n",
    "    feasibles.append(feasible)\n",
    "    \n",
    "    save_data[\"results\"] = [lams,\n",
    "                deb_preds,\n",
    "                lasso_preds,\n",
    "                y_tests,\n",
    "                kappas,\n",
    "                feasibles]\n",
    "        \n",
    "    print(\"Saving Data\")\n",
    "    time.sleep(1)\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    file_name = \"JM_\"+str(dataset)+\"_\"+timestr+\".pickle\"\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    pickle.dump(save_data, open(file_path, \"wb\"))\n",
    "    \n",
    "    return save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_LinReg_expts(dataset, fit_intercept, folder_path):\n",
    "\n",
    "    # function to potentially parallelize experiments across various values of p, n, s and save data in pkl file\n",
    "    # Runs Linear Regressionon on Real Datasets\n",
    "    save_data = OrderedDict()\n",
    "    \n",
    "    save_data[\"main_reg_params\"]=\"LinReg\"\n",
    "    save_data[\"dataset\"]=str(dataset)\n",
    "    save_data[\"fit_intercept\"]=str(fit_intercept)\n",
    "    save_data[\"output\"] = \"main_preds, y_test, kappa, mu_y\"\n",
    "    save_data[\"lam\"] = lams[0]\n",
    "    save_data[\"lam_method\"] = lams[1]\n",
    "\n",
    "    if dataset==\"Triazines\":\n",
    "        data=load_triazines(test_size=.20)\n",
    "    elif dataset==\"Wine\":\n",
    "        data=load_wine()\n",
    "    elif dataset==\"Parkinson\":\n",
    "        data=load_parkinson()\n",
    "    elif dataset==\"Fertility\":\n",
    "        data=load_fertility()\n",
    "    elif dataset==\"Fire\":\n",
    "        data=load_forest_fires()\n",
    "        \n",
    "    X_train, y_train, X_test, y_test = data\n",
    "    train_n, p = X_train.shape\n",
    "    test_n, _ = X_test.shape\n",
    "    #print(test_n)\n",
    "    \n",
    "    print(\"Starting\")\n",
    "\n",
    "    main_preds=[]\n",
    "    y_tests=[] \n",
    "    kappas=[]\n",
    "\n",
    "    main_pred, y_test, kappa = run_LinReg_expt((X_train, y_train, X_test, y_test), fit_intercept=fit_intercept)\n",
    "    main_preds.append([i for i in main_pred])\n",
    "    y_tests.append(y_test)\n",
    "    kappas.append(kappa)\n",
    "    \n",
    "    save_data[\"results\"] = [main_preds,\n",
    "                y_tests,\n",
    "                kappas]\n",
    "        \n",
    "    print(\"Saving Data\")\n",
    "    time.sleep(1)\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    file_name = \"LinReg_\"+str(dataset)+\"_\"+timestr+\".pickle\"\n",
    "    \n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    pickle.dump(save_data, open(file_path, \"wb\"))\n",
    "    \n",
    "    return save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigma=1.0\n",
    "computer_cpus = psutil.cpu_count()\n",
    "main_reg_params = [({\"method\" : \"Lasso\"}, 48, computer_cpus//48), ({\"method\" : \"Ridge\"}, 12, computer_cpus//12), ({\"method\" : \"Elastic\"}, 48, computer_cpus//48)]\n",
    "datasets=[\"Fertility\", \"Triazines\", \"Fire\", \"Wine\", \"Parkinson\"]\n",
    "JM_aux_params=[(np.logspace(-7, 2, num=100), \"grid\")]\n",
    "cv=True       \n",
    "fit_intercept=False\n",
    "path_options=\"JM_Real\"\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "folder_path=str(now.month)+\"-\"+str(now.day)+\"-\"+path_options\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total=0\n",
    "for lams in JM_aux_params:\n",
    "    for dataset in datasets:\n",
    "        total+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for main_reg_param, chunk_size, threads in main_reg_params:\n",
    "    for lams in JM_aux_params:\n",
    "        for dataset in datasets:\n",
    "            count+=1\n",
    "            print(\"{0:.0%}\".format(float(count)/total)+\" Done\")\n",
    "            data_cv_true_JM = save_JM_expts(dataset=dataset, main_reg_param=main_reg_param, cv=cv, fit_intercept=fit_intercept, sigma=sigma, lams=lams, threads=threads, parallel_params=(chunk_size, threads), folder_path=folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_options=\"LinReg_Real\"\n",
    "now = datetime.datetime.now()\n",
    "folder_path=str(now.month)+\"-\"+str(now.day)+\"-\"+path_options\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "for dataset in datasets:\n",
    "    count+=1\n",
    "    print(\"{0:.0%}\".format(float(count)/total)+\" Done\")\n",
    "    data_lin_reg = save_LinReg_expts(dataset=dataset, fit_intercept=True, folder_path=folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
